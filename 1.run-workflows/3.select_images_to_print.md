Select images to print
================

``` r
knitr::opts_chunk$set(echo = TRUE)
library(glue)
library(magrittr)
library(stringr)
library(tidyverse)
```

## Prepare load\_data

``` r
load_data <- 
  list.files("load_data_csv/", pattern = "load_data.csv", full.names = T, recursive = T)  %>%
  map_df(read_csv)

convert_to_s3_url <- function(pathname, filename)  {
  file.path(
      str_replace(pathname, 
              "/home/ubuntu/bucket", 
              "https://s3.amazonaws.com/imaging-platform"),
      filename
  )
  
}

channels <- c("DNA", "ER", "RNA", "AGP", "Mito")

for (channel in channels) {
  url_sym <- rlang::sym(str_c("URL_Orig", channel))
  
  path_sym <- rlang::sym(str_c("PathName_Orig", channel))
   
  file_sym <- rlang::sym(str_c("FileName_Orig", channel))
   
  load_data %<>% 
    mutate(!!url_sym := convert_to_s3_url((!!path_sym), (!!file_sym)))
  
}
```

## Get metadata

``` r
datasets <- 
  tribble(
    ~batch, ~plate,
    "NCP_STEM_1", "BR_NCP_STEM_1",
    "NCP_PROGENITORS_1", "BR_NCP_PROGENITORS_1"
  )

metadata <-
  map2_df(datasets$batch,
          datasets$plate,
          function(batch, plate) {
            read_tsv(
              file.path("metadata", glue("{batch}/platemap/{plate}.txt")),
              col_types = cols_only(
                plate_map_name = "c",
                well_position = "c",
                line_ID = "c",
                line_condition = "c",
                line_source = "c",
                plating_density = "i"
              )
            ) %>%
              distinct()
          })

metadata %<>%
  rename(Metadata_Plate = plate_map_name, 
         Metadata_Well = well_position,
         Metadata_line_ID = line_ID,
         Metadata_line_condition = line_condition,
         Metadata_line_source = line_source,
         Metadata_plating_density = plating_density)
```

## Report plating densities

``` r
metadata %>% group_by(Metadata_Plate, Metadata_plating_density) %>% tally()
```

    ## # A tibble: 2 x 3
    ## # Groups:   Metadata_Plate [2]
    ##   Metadata_Plate       Metadata_plating_density     n
    ##   <chr>                                   <int> <int>
    ## 1 BR_NCP_PROGENITORS_1                    10000   384
    ## 2 BR_NCP_STEM_1                           10000   384

## Sample one well per cell line

``` r
set.seed(5)

metadata_sampled <-
  metadata %>%
  group_by(Metadata_line_ID) %>%
  sample_n(1) %>%
  ungroup()
```

## Select a fixed field (a.k.a site)

``` r
fieldIDs <- c(3, 5)
```

## Select images to be printed

``` r
filenames_header <- paste0("FileName_Orig", channels)

images <- 
  load_data %>%
  select(Metadata_Plate, Metadata_Well, Metadata_Row, Metadata_FieldID, matches("^URL_"), one_of(filenames_header)) %>%
  inner_join(metadata_sampled, by = c("Metadata_Plate", "Metadata_Well")) %>%
  filter(Metadata_FieldID %in% fieldIDs) %>%
  select(matches("^Metadata"), matches("^URL"), matches("^FileName_Orig"))

images_pivoted <-
  images %>%
  select(Metadata_Plate,  Metadata_Well, matches("^URL_")) %>%
  gather(Metadata_Channel, URL, -Metadata_Plate, -Metadata_Well) %>%
  mutate(filename = basename(URL)) %>%
  select(Metadata_Plate, Metadata_Well, Metadata_Channel, filename, URL)

images_pivoted %>% 
  write_csv("data/sample_images.csv")
```

``` r
images %>%
  select(matches("^Metadata"),  matches("^FileName_Orig")) %>%
  write_csv("data/sample_images_metadata.csv")
```

Run this on command line to download the images:

``` sh
IMAGE_DIR=/tmp/ncp

mkdir -p $IMAGE_DIR

cut -d"," -f1 data/sample_images.csv | grep -v Metadata_Plate| sort -u > /tmp/plates.txt

parallel -a /tmp/plates.txt --no-run-if-empty mkdir -p $IMAGE_DIR/{} 

parallel \
 --header ".*\n" \
 -C "," \
 -a data/sample_images.csv \
 --eta \
 --joblog ${IMAGE_DIR}/download.log \
 wget -q -O ${IMAGE_DIR}/{1}/{4} {5}
```
