{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the previous notebook, we investigate what happens when the low cell count wells are removed.\n",
    "\n",
    "Conclusion: Removing the low cell count wells vastly improves the signal and accuracy of logistic regression. Looking at the images, it's clear that those wells were mostly empty or had cells missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns \n",
    "import math\n",
    "import statistics\n",
    "import random\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import adjusted_rand_score, homogeneity_score\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     16,
     33
    ]
   },
   "outputs": [],
   "source": [
    "def id_to_cluster(linkage_data, agg_features_df):\n",
    "    \"\"\"\n",
    "    linkage_data: array of cluster numbers\n",
    "    agg_features_df: df of aggregated features to merge, index must match order of linkage_data\n",
    "    Returns a df with aggregated cp data and cluster number for each id\n",
    "    \"\"\"\n",
    "    # Get cluster number with the aggregated feature data\n",
    "    clusters_hierarchal_df = pd.DataFrame(data=linkage_data, index=agg_features_df.index)\n",
    "    clusters_hierarchal_df.rename(columns={0:'cluster_num'}, inplace=True)\n",
    "    clusters_hierarchal_df = clusters_hierarchal_df.merge(agg_features_df, how='left', left_index=True, right_index=True)\n",
    "\n",
    "    # Get the cell profiler features by cluster\n",
    "    cp_features_by_cluster = clusters_hierarchal_df.groupby(by='cluster_num').mean()\n",
    "    \n",
    "    return clusters_hierarchal_df\n",
    "\n",
    "def hierarchical_cluster(df, threshold, show=False):\n",
    "    \"\"\"\n",
    "    Returns df of cluster features\n",
    "    \"\"\"\n",
    "    threshold=threshold\n",
    "    Z1 = linkage(df, 'ward')\n",
    "    flat_linkage1 = fcluster(Z1, t=threshold, criterion='distance')\n",
    "    cluster_features1 = id_to_cluster(flat_linkage1, df)\n",
    "    \n",
    "    if show:\n",
    "        plt.figure(figsize=(12, df.shape[0]/4))\n",
    "        plt.axvline(x=threshold)\n",
    "        label = [str(i) + ' ' + j for i, j in zip(flat_linkage1.tolist(), df.index.tolist())]\n",
    "        plt.title('Clusters based on cell profiler features')\n",
    "        dend1 = dendrogram(Z1, color_threshold=threshold, orientation='left', leaf_font_size=10, labels=label)\n",
    "    return cluster_features1\n",
    "\n",
    "def km_cluster(df, num_clusters, random_state=2):\n",
    "    \"\"\"\n",
    "    returns df of cluster features\n",
    "    \"\"\"\n",
    "    km = KMeans(n_clusters=num_clusters, random_state=random_state).fit(df)\n",
    "    return id_to_cluster(km.labels_, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (312, 508)\n"
     ]
    }
   ],
   "source": [
    "# Progenitors data\n",
    "from pathlib import Path\n",
    "path = os.getcwd()\n",
    "base_dir = str(Path(path).parent)\n",
    "\n",
    "switch_isogenic_labels = True\n",
    "human_only=True\n",
    "\n",
    "#FS data\n",
    "progenitors = pd.read_csv(base_dir + '/3.analysis/feature_sets/Progenitors/0714_stdev_corr_fs.csv', index_col=0)\n",
    "\n",
    "exclude = ['5', '6', '33', '12', '16']\n",
    "try:\n",
    "    idx = [i for i in progenitors.index.tolist() if i.split('_')[2] not in exclude] # Exclude patient number\n",
    "    progenitors = progenitors[progenitors.index.isin(idx)]\n",
    "except: pass\n",
    "\n",
    "if human_only:\n",
    "    progenitors = progenitors[progenitors.index.str.contains('human')]\n",
    "\n",
    "print ('shape: {}'.format(progenitors.shape))\n",
    "\n",
    "labels = progenitors.index.tolist()\n",
    "if switch_isogenic_labels:\n",
    "    for i in range(len(labels)):\n",
    "        if 'isogenic_deletion' in labels[i]:\n",
    "            labels[i] = labels[i].replace('isogenic_deletion', 'temp')\n",
    "    for i in range(len(labels)):\n",
    "        if 'isogenic_control' in labels[i]:\n",
    "            labels[i] = labels[i].replace('isogenic_control', 'isogenic_deletion')            \n",
    "        if 'temp' in labels[i]:\n",
    "            labels[i] = labels[i].replace('temp', 'isogenic_control')                    \n",
    "progenitors.index = labels\n",
    "progenitors_orig = progenitors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (352, 559)\n"
     ]
    }
   ],
   "source": [
    "# STEM data\n",
    "# Or use my FS data\n",
    "stem = pd.read_csv(base_dir + '/3.analysis/feature_sets/STEM01/0621_stdev_corr_fs.csv', index_col=0)\n",
    "\n",
    "\n",
    "try:\n",
    "    idx = [i for i in stem.index.tolist() if i.split('_')[-1] not in exclude]\n",
    "    stem = stem[stem.index.isin(idx)]\n",
    "except: pass\n",
    "\n",
    "if human_only:\n",
    "    stem = stem[stem.index.str.contains('human')]\n",
    "    \n",
    "print ('shape: {}'.format(stem.shape))\n",
    "\n",
    "labels = stem.index.tolist()\n",
    "if switch_isogenic_labels:\n",
    "    for i in range(len(labels)):\n",
    "        if 'isogenic_deletion' in labels[i]:\n",
    "            labels[i] = labels[i].replace('isogenic_deletion', 'temp')\n",
    "    for i in range(len(labels)):\n",
    "        if 'isogenic_control' in labels[i]:\n",
    "            labels[i] = labels[i].replace('isogenic_control', 'isogenic_deletion')            \n",
    "        if 'temp' in labels[i]:\n",
    "            labels[i] = labels[i].replace('temp', 'isogenic_control')                    \n",
    "stem.index = labels\n",
    "stem_orig = stem.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n",
      "1.0 0.7596153846153846\n"
     ]
    }
   ],
   "source": [
    "# SPLIT DATA BASED ON PATIENT NUMBER STEM\n",
    "random.seed(3)\n",
    "stem['label'] = stem.index.str.split('_').map(lambda x: x[1])\n",
    "stem['patient_num'] = stem.index.str.split('_').map(lambda x: x[2])\n",
    "\n",
    "patients = list(set(stem['patient_num']))\n",
    "random.shuffle(patients)\n",
    "train_nums = patients[0:31]\n",
    "test_nums = patients[31:]\n",
    "\n",
    "train_df = stem[stem['patient_num'].isin(train_nums)]\n",
    "test_df = stem[stem['patient_num'].isin(test_nums)]\n",
    "\n",
    "stem_xtrain = train_df.drop(['label', 'patient_num'], axis=1)\n",
    "stem_ytrain = train_df['label']\n",
    "stem_xtest = test_df.drop(['label', 'patient_num'], axis=1)\n",
    "stem_ytest = test_df['label']\n",
    "                             \n",
    "print(len(stem_xtrain) + len(stem_xtest))\n",
    "\n",
    "logr1 = LogisticRegression(random_state=2, penalty='l2', C=1).fit(stem_xtrain, stem_ytrain)\n",
    "print(logr1.score(stem_xtrain, stem_ytrain), logr1.score(stem_xtest, stem_ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n",
      "1.0 0.6818181818181818\n"
     ]
    }
   ],
   "source": [
    "# SPLIT DATA BASED ON PATIENT NUMBER PROGENITORS\n",
    "random.seed(3)\n",
    "progenitors['label'] = progenitors.index.str.split('_').map(lambda x: x[1])\n",
    "progenitors['patient_num'] = progenitors.index.str.split('_').map(lambda x: x[2])\n",
    "\n",
    "patients = list(set(progenitors['patient_num']))\n",
    "random.shuffle(patients)\n",
    "train_nums = patients[0:28]\n",
    "test_nums = patients[28:]\n",
    "\n",
    "train_df = progenitors[progenitors['patient_num'].isin(train_nums)]\n",
    "test_df = progenitors[progenitors['patient_num'].isin(test_nums)]\n",
    "\n",
    "progenitors_xtrain = train_df.drop(['label', 'patient_num'], axis=1)\n",
    "progenitors_ytrain = train_df['label']\n",
    "progenitors_xtest = test_df.drop(['label', 'patient_num'], axis=1)\n",
    "progenitors_ytest = test_df['label']\n",
    "                             \n",
    "print(len(progenitors_xtrain) + len(progenitors_xtest))\n",
    "\n",
    "logr1 = LogisticRegression(random_state=2, penalty='l2', C=1, max_iter=150).fit(progenitors_xtrain, progenitors_ytrain)\n",
    "print(logr1.score(progenitors_xtrain, progenitors_ytrain), logr1.score(progenitors_xtest, progenitors_ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing under 200 ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     17
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (348, 508)\n"
     ]
    }
   ],
   "source": [
    "# Progenitors data\n",
    "from pathlib import Path\n",
    "path = os.getcwd()\n",
    "base_dir = str(Path(path).parent)\n",
    "\n",
    "switch_isogenic_labels = True\n",
    "human_only=True\n",
    "\n",
    "#FS data\n",
    "progenitors = pd.read_csv(base_dir + '/3.analysis/feature_sets/Progenitors/0714_stdev_corr_fs.csv', index_col=0)\n",
    "\n",
    "if human_only:\n",
    "    progenitors = progenitors[progenitors.index.str.contains('human')]\n",
    "\n",
    "print ('shape: {}'.format(progenitors.shape))\n",
    "\n",
    "labels = progenitors.index.tolist()\n",
    "if switch_isogenic_labels:\n",
    "    for i in range(len(labels)):\n",
    "        if 'isogenic_deletion' in labels[i]:\n",
    "            labels[i] = labels[i].replace('isogenic_deletion', 'temp')\n",
    "    for i in range(len(labels)):\n",
    "        if 'isogenic_control' in labels[i]:\n",
    "            labels[i] = labels[i].replace('isogenic_control', 'isogenic_deletion')            \n",
    "        if 'temp' in labels[i]:\n",
    "            labels[i] = labels[i].replace('temp', 'isogenic_control')                    \n",
    "progenitors.index = labels\n",
    "progenitors_orig = progenitors.copy()\n",
    "\n",
    "# Merge progenitors with cell_number_object_number\n",
    "prog_cts = pd.read_csv(base_dir + '/1.run-workflows/profiles/NCP_PROGENITORS_1/BR_NCP_PROGENITORS_1.csv.gz', index_col=0)\n",
    "prog_cts = prog_cts[['Metadata_Well', 'Cells_Number_Object_Number']]\n",
    "\n",
    "progenitors['well'] = progenitors.index.str.split('_').map(lambda x: x[-1])\n",
    "progenitors['well'] = progenitors.index.str.split('_').map(lambda x: x[-1])\n",
    "progenitors['idx'] = progenitors.index\n",
    "progenitors = progenitors.merge(prog_cts, how='inner', left_on='well', right_on='Metadata_Well').drop(['well', 'Metadata_Well'], axis=1)\n",
    "progenitors.set_index('idx', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n",
      "1.0 0.7415730337078652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-21f4773bce7b>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  progenitors_over200['label'] = progenitors_over200.index.str.split('_').map(lambda x: x[1])\n",
      "<ipython-input-9-21f4773bce7b>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  progenitors_over200['patient_num'] = progenitors_over200.index.str.split('_').map(lambda x: x[2])\n"
     ]
    }
   ],
   "source": [
    "progenitors_over200 = progenitors[progenitors['Cells_Number_Object_Number']>200]\n",
    "\n",
    "# SPLIT DATA BASED ON PATIENT NUMBER progenitors_over200\n",
    "random.seed(2)\n",
    "progenitors_over200['label'] = progenitors_over200.index.str.split('_').map(lambda x: x[1])\n",
    "progenitors_over200['patient_num'] = progenitors_over200.index.str.split('_').map(lambda x: x[2])\n",
    "\n",
    "patients = list(set(progenitors_over200['patient_num']))\n",
    "random.shuffle(patients)\n",
    "train_nums = patients[0:24]\n",
    "test_nums = patients[24:]\n",
    "\n",
    "train_df = progenitors_over200[progenitors_over200['patient_num'].isin(train_nums)]\n",
    "test_df = progenitors_over200[progenitors_over200['patient_num'].isin(test_nums)]\n",
    "\n",
    "progenitors_over200_xtrain = train_df.drop(['label', 'patient_num', 'Cells_Number_Object_Number'], axis=1)\n",
    "progenitors_over200_ytrain = train_df['label']\n",
    "progenitors_over200_xtest = test_df.drop(['label', 'patient_num', 'Cells_Number_Object_Number'], axis=1)\n",
    "progenitors_over200_ytest = test_df['label']\n",
    "                             \n",
    "print(len(progenitors_over200_xtrain) + len(progenitors_over200_xtest))\n",
    "\n",
    "logr1 = LogisticRegression(random_state=2, penalty='l2', C=1, max_iter=150).fit(progenitors_over200_xtrain, progenitors_over200_ytrain)\n",
    "print(logr1.score(progenitors_over200_xtrain, progenitors_over200_ytrain), logr1.score(progenitors_over200_xtest, progenitors_over200_ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9946808510638298 0.9506172839506173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-dd21e6b80b3e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  progenitors_over200['label'] = progenitors_over200.index.str.split('_').map(lambda x: x[1])\n"
     ]
    }
   ],
   "source": [
    "progenitors_over200['label'] = progenitors_over200.index.str.split('_').map(lambda x: x[1])\n",
    "progenitors_over200_xtrain, progenitors_over200_xtest, progenitors_over200_ytrain, progenitors_over200_ytest = train_test_split(progenitors_over200.drop(['label', 'Cells_Number_Object_Number', 'patient_num'], axis=1), progenitors_over200['label'], \n",
    "                                                                    test_size=0.3, random_state=4)\n",
    "# print(len(progenitors_over200_xtrain) + len(progenitors_over200_xtest))\n",
    "\n",
    "logr2 = LogisticRegression(random_state=2, penalty='l2', C=1, max_iter=130).fit(progenitors_over200_xtrain, progenitors_over200_ytrain)\n",
    "print(logr2.score(progenitors_over200_xtrain, progenitors_over200_ytrain), logr2.score(progenitors_over200_xtest, progenitors_over200_ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
